{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "# Disable copysettingwarning\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "# Import berth_visits\n",
    "berth_visits = pd.read_csv('data/berth_visits.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gather unique locations in berth_visits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "locations = {x:'' for x in set(berth_visits['location_id'])}\n",
    "locations"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gather these same locations using the PortMaps API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "# ~ 1400 locations so two calls needed\n",
    "url1 = \"https://api.portofrotterdam.com/v1/datascience/148/query?where=OBJECTID<=1000&outFields=*&f=geojson\"\n",
    "url2 = \"https://api.portofrotterdam.com/v1/datascience/148/query?where=OBJECTID>1000&outFields=*&f=geojson\"\n",
    "headers = {'apikey': '<API_KEY>'} # informeer bij Bram voor deze key indien nodig\n",
    " \n",
    "# Call one\n",
    "req1 = requests.get(url1, headers=headers)\n",
    "response1 = json.loads(req1.text)\n",
    "\n",
    "# Call two\n",
    "req2 = requests.get(url2, headers=headers)\n",
    "response2 = json.loads(req2.text)\n",
    "\n",
    "# Select\n",
    "response1, response2 = response1['features'], response2['features']\n",
    "\n",
    "# Merge\n",
    "response = response1 + response2\n",
    "\n",
    "# Retrieve only relevant information\n",
    "port_locations = [[x['properties']['ZZ_CODE'],x['properties']['ZZLIGPLG'],x['properties']['ZZHVNAAM']] for x in response]\n",
    "port_locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "codes = pd.DataFrame(port_locations, columns=['Code','Locatie 1', 'Locatie 2'])\n",
    "codes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Export (the conversion is done by hand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unieke_locaties = set(codes['Locatie 2'])\n",
    "unieke_locaties = pd.DataFrame(unieke_locaties, columns=['Locatie PORTMAPS'])\n",
    "unieke_locaties['Locatie EVIDES'] = ''\n",
    "\n",
    "# Export naar excel\n",
    "unieke_locaties.to_excel('data/locaties.xlsx')\n",
    "unieke_locaties"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unieke_locaties = pd.read_excel('data/locaties_aangevuld.xlsx')\n",
    "unieke_locaties = unieke_locaties.drop(columns=['Unnamed: 0', 'Unnamed: 3', 'Unnamed: 4'])\n",
    "unieke_locaties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "codes['Locatie EVIDES'] = ''\n",
    "codes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add Evides location information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "codes['Locatie EVIDES'] = [unieke_locaties['Locatie EVIDES'][unieke_locaties['Locatie PORTMAPS']==x].values[0] for x in codes['Locatie 2']]\n",
    "codes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge with berth_visits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename 'Code' column to location_id\n",
    "codes = codes.rename(columns={\"Code\": \"location_id\"})\n",
    "berth_visits_merged = pd.merge(berth_visits, codes, on='location_id', how=\"left\")\n",
    "berth_visits_merged"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great, now we can start extracting AIS points. Let's import the Evides data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evides = pd.read_csv('../1. Exploratory Analysis/Data/Cleaned data/evides_cleaned2.csv')\n",
    "evides = evides.drop(columns=['Unnamed: 0'])\n",
    "evides"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll create two new columns: longitude and latitude. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evides['Latitude'], evides['Longitude'] = '', ''\n",
    "evides"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's go through the steps to fill the latitude and longitude columns. We start with one shipment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get one shipment\n",
    "evides.loc[8000]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first try to find a match based both on date, ENI and location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset = berth_visits_merged[(berth_visits_merged['eni']==evides['ENI'].loc[8000]) \n",
    "                             & (berth_visits_merged['Locatie EVIDES']==evides['Haven'].loc[8000]) \n",
    "                             & (berth_visits_merged['start_date']<=evides['Datum'].loc[8000])\n",
    "                             & (berth_visits_merged['end_date']>=evides['Datum'].loc[8000])]\n",
    "subset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In case this is not possible, we try to find a match based on ENI and location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_date = '2022-07-05'\n",
    "\n",
    "subset = berth_visits_merged[(berth_visits_merged['eni']==evides['ENI'].loc[1]) \n",
    "                             & (berth_visits_merged['Locatie EVIDES']==evides['Haven'].loc[1])]\n",
    "\n",
    "subset['day_diff'] = [datetime.strptime(sample_date, '%Y-%m-%d')-datetime.strptime(subset['start_date'].loc[x], '%Y-%m-%dT%H:%M:%S.%fZ')\n",
    "for x in subset.index]\n",
    "\n",
    "subset['day_diff'] = [abs(x.days) for x in subset['day_diff']]\n",
    "\n",
    "subset = subset.sort_values(by='day_diff')\n",
    "\n",
    "subset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From here we select the entry closest in date. If this is also not possible, we select valid berth coordinates based on the location. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset = berth_visits_merged[berth_visits_merged['Locatie EVIDES']==evides['Haven'].loc[0]]\n",
    "subset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But first, we need to make sure all records in our Evides dataset can be converted. We've already merged based on all existing names that we received through the PortMaps API. This does not the include the following names, with the corresponding amount of rows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in set(evides['Haven']):\n",
    "    if i not in set(berth_visits_merged['Locatie EVIDES']):\n",
    "        print(i, len(evides[evides['Haven']==i]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fortunately not a lot of rows are affected by this, but we should take care of this nevertheless. We will convert these names to the nearest harbour which does have bound location in the berth_visits dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_changes = {\n",
    "'Westerkade':'Wilhelminakade',\n",
    "'Maassluis':'Nieuwe Maas',\n",
    "'Pelgrimskade':'REMOVE',\n",
    "'Stena Line':'Rijnhaven',\n",
    "'Jobskade/Jobshaven':'Boompjes',\n",
    "'Pionier':'Hartelkanaal',\n",
    "'Kemira':'Botlek',\n",
    "'zuiddiep':'REMOVE',\n",
    "'Maaskade':'Rijnhaven',\n",
    "'Radio Holland':'Schiehaven',\n",
    "'Wilhelminakade':'Rijnhaven',\n",
    "'krimpen a/d IJssel':'REMOVE'\n",
    "}\n",
    "\n",
    "for i in name_changes:\n",
    "    evides['Haven'][evides['Haven']==i] = name_changes[i]\n",
    "\n",
    "# Drop observations with value 'REMOVE'\n",
    "evides = evides[evides['Haven'] != 'REMOVE']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, finally, let's extract the AIS coordinates!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in evides.index:\n",
    "    # Attempt to find a perfect Match\n",
    "    subset = berth_visits_merged[(berth_visits_merged['eni']==evides['ENI'].loc[i]) \n",
    "                             & (berth_visits_merged['Locatie EVIDES']==evides['Haven'].loc[i]) \n",
    "                             & (berth_visits_merged['start_date']<=evides['Datum'].loc[i])\n",
    "                             & (berth_visits_merged['end_date']>=evides['Datum'].loc[i])]\n",
    "    \n",
    "    if len(subset) > 0:\n",
    "        # Extract longitude\n",
    "        evides['Latitude'].loc[i] = subset['latitude_enter'].reset_index(drop=True)[0]\n",
    "        evides['Longitude'].loc[i] = subset['longitude_enter'].reset_index(drop=True)[0]\n",
    "\n",
    "        print(\"Index\", str(i), \"Method 1\")\n",
    "\n",
    "    # Then attempt to find a match based on ENI and Location , if necessary. \n",
    "    if evides['Latitude'].loc[i] == '' and evides['Longitude'].loc[i] == '':\n",
    "        # Create new subset\n",
    "        subset = berth_visits_merged[(berth_visits_merged['eni']==evides['ENI'].loc[i]) \n",
    "                                & (berth_visits_merged['Locatie EVIDES']==evides['Haven'].loc[i])]\n",
    "        \n",
    "        subset['day_diff'] = [datetime.strptime(sample_date, '%Y-%m-%d')-datetime.strptime(subset['start_date'].loc[x], '%Y-%m-%dT%H:%M:%S.%fZ')\n",
    "        for x in subset.index]\n",
    "\n",
    "        subset['day_diff'] = [abs(x.days) for x in subset['day_diff']]\n",
    "        subset = subset.sort_values(by='day_diff')\n",
    "        \n",
    "        if len(subset) > 0:\n",
    "            # Extract longitude\n",
    "            evides['Latitude'].loc[i] = subset['latitude_enter'].reset_index(drop=True)[0]\n",
    "            evides['Longitude'].loc[i] = subset['longitude_enter'].reset_index(drop=True)[0]\n",
    "\n",
    "            print(\"Index\", str(i), \"Method 2\")\n",
    "        \n",
    "    # Then attempt to find a match based only on location, if necessary. \n",
    "    if evides['Latitude'].loc[i] == '' and evides['Longitude'].loc[i] == '':\n",
    "        # Create new subset\n",
    "        subset = berth_visits_merged[berth_visits_merged['Locatie EVIDES']==evides['Haven'].loc[i]]\n",
    "        \n",
    "        if len(subset) > 0:\n",
    "            # Extract longitude\n",
    "            evides['Latitude'].loc[i] = subset['latitude_enter'].reset_index(drop=True)[0]\n",
    "            evides['Longitude'].loc[i] = subset['longitude_enter'].reset_index(drop=True)[0]\n",
    "\n",
    "            print(\"Index\", str(i), \"Method 3\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evides.to_csv('evides_withAIS.csv')  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
