{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notebook: Cleaning\n",
    "\n",
    "In this notebook, we'll take care of the cleaning of the Evides and the Fixed Supply Points datasets. We'll start with Evides."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import jellyfish\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "# Import data\n",
    "evides = pd.read_csv('evides_2022.csv') \n",
    "\n",
    "# Remove duplicates & 'transactie' column\n",
    "evides = evides.drop('Transactie', axis=1)\n",
    "evides.drop_duplicates(inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning - Evides\n",
    "First, let us assess the missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mv = pd.DataFrame(data=evides.isnull().sum(), columns=['Missing values'])\n",
    "mv['% of total'] = round(mv['Missing values'] / len(evides) * 100, 2)\n",
    "mv"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset does contain some missing values, but fortunately this affects only a very small percentage of observations. In addition to missing values, we'll also need to take into account values which are wrongly spelled or otherwise invalid. For example, the ENI-number should be equal to 8 arabic numbers. The 'Klant' column does contain lots of missing values. However, since this column is of no value for this research, it can be removed entirely. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evides = evides.drop('Klant', axis=1)\n",
    "evides.dtypes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, ENI is currently stored as a string (object). ENI is a tricky column, for the following reasons.\n",
    "\n",
    "* Some values start with a leading zero ('01234567'), whilst others don't ('1234567'). Regardless, these are still the same ENI IDs. \n",
    "* Some values contain less than 8 numbers ('123456')\n",
    "* Some values contain weird formatting ('*1234567')\n",
    "* Some values are missing (279 in total)\n",
    "* Some values are misaligned (wrong ENI assigned to a shipment)\n",
    "\n",
    "In order to resolve these issues, we take the following steps, in the following order.\n",
    "\n",
    "1. We'll convert ENI values to numeric in order to get rid of the leading zero. This is done in order to make sure that there are no differences between ENI values for the same boats.\n",
    "2. Since an ENI consists of 8 values by definition (or 7 here, since the leading zero was removed), we convert all ENI values which contain less than 7 characters to NaN. \n",
    "3. We now convert all NaN values to 0, to allow for int conversion.\n",
    "4. We then convert the ENI column to integers to get rid of hidden .0's, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Convert ENI values to numeric\n",
    "evides['ENI'] = pd.to_numeric(evides['ENI'], errors='coerce') # convert to numeric type\n",
    "\n",
    "# 2. Convert invalid ENI values to NaN (affects 110 values)\n",
    "evides['ENI'].loc[evides.ENI < 1000000] = 0\n",
    "\n",
    "# Set other NaNs to 0 as well\n",
    "evides['ENI'][evides['ENI'].isnull()] = 0\n",
    "\n",
    "# 3. Convert to INT to get rid of hidden '.0'\n",
    "evides['ENI'] = evides['ENI'].astype('int64', errors='ignore')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've done this, we can start looking at ENI numbers which are too small (6 characters). We then convert the column back to a string format. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(evides[evides['ENI']==0]))\n",
    "unresolved_indexes = []\n",
    "for i in evides[evides['ENI'] == 0].index:\n",
    "    # Get index of row with ENI = 0\n",
    "    row = evides.loc[i]\n",
    "    \n",
    "    #print(row)\n",
    "\n",
    "    #print(row)\n",
    "\n",
    "    # Get other records with the same boat name and boat type \n",
    "    obj = evides[(evides['Scheepsnaam'] == row.Scheepsnaam) & (evides['Scheepstype']== row.Scheepstype)]\n",
    "    \n",
    "    #print(obj)\n",
    "    \n",
    "    if len(obj) == 0:\n",
    "        unresolved_indexes.append(i)\n",
    "\n",
    "    \n",
    "    else:    \n",
    "        # Group these other records by count of ENI\n",
    "        grouped_obj = obj.groupby(['ENI']).size().sort_values(ascending=False)\n",
    "\n",
    "        # Replace ENI by most frequently occuring ENI for this ship name and ship type\n",
    "        row.ENI = grouped_obj.index[0]\n",
    "\n",
    "        if row.ENI == 0:\n",
    "            try:\n",
    "                row.ENI = grouped_obj.index[1]\n",
    "\n",
    "            except:\n",
    "                unresolved_indexes.append(i)\n",
    "\n",
    "        evides.loc[i] = row\n",
    "\n",
    "        #print(row.ENI, grouped_obj[row.ENI])\n",
    "\n",
    "evides = evides[~evides.index.isin(unresolved_indexes)]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Through this method, we were able to recover 262 out of 403 rows with a missing or wrongly formatted ENI value. We'll now convert the ENIs back to a string format. Since many ENIs now have a length of 7, we'll readd the leading zero's. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evides['ENI'] = evides['ENI'].astype('str')\n",
    "\n",
    "for i in evides['ENI']:\n",
    "    # if len == 7, then immediately add the leading 0 to all instances of this ENI. \n",
    "    if len(i) == 7:\n",
    "        evides['ENI'][evides['ENI']==i] = '0' + i\n",
    "\n",
    "evides['ENI']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great, all ENIs now have the right length and format. Unfortunately, there are other issues. For example, the records below show observations that belong to the ship 'nijmegen max', with ENI 02338661. However, there are also two records with ship name 'atlantic prestige'. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evides[evides['ENI']=='02338661']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evides[evides['Scheepsnaam']=='atlantic prestige']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see here that the actual ENI of the atlantic prestige is quite close to the ENI of the nijmegen max, yet it is slightly different. Let's see how often we get different names for the same ENI. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eni_data = pd.DataFrame(evides.groupby(['ENI','Scheepsnaam']).size())\n",
    "eni_data = eni_data.add_suffix('_Count').reset_index()\n",
    "eni_data.columns = ['ENI','Scheepsnaam','Count']\n",
    "\n",
    "eni_data['Occurances'] = [len(eni_data[eni_data['ENI']==x]) for x in eni_data['ENI']]\n",
    "eni_data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This table shows all ENIs, corresponding ship names and its counts. The column \"occurances\" shows the count of unique ENI IDs in this table. By subsetting for 'Occurances' > 1, we can find all ENIs that will need to be examined. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eni_data = eni_data[eni_data['Occurances'] > 1]\n",
    "print(\"Unique ENI's left: {w}\".format(w=len(set(eni_data['ENI']))))\n",
    "eni_data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As it turns out, there are also many instances of ENI-Ship name combinations which are almost identical, but not fully. For example, 'fairplay 11' and 'fairplay XI' clearly refer to the same ship. We'll assume that vessels whose names differ only by 1, 2 or 3, 4 or 5 characters are the same name, but spelled differently. We can only do this for ENIs that occur two times, since we will be comparing two names. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create same_name column\n",
    "eni_data['Same name'] = [999 for x in eni_data['ENI']]\n",
    "\n",
    "# Fill it for occurances = 2\n",
    "eni_data['Same name'][eni_data['Occurances']==2] = [jellyfish.damerau_levenshtein_distance(\n",
    "    eni_data['Scheepsnaam'][eni_data['ENI']==x].values[0],\n",
    "    eni_data['Scheepsnaam'][eni_data['ENI']==x].values[1]                        \n",
    "    ) for x in eni_data['ENI'][eni_data['Occurances']==2]]\n",
    "\n",
    "# Print it\n",
    "eni_data.sort_values(by=\"Same name\", ascending=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's get rid of all values for which \"Same name\" <= 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eni_data = eni_data[eni_data['Same name'] > 5]\n",
    "print(\"Unique ENI's left: {w}\".format(w=len(set(eni_data['ENI']))))\n",
    "eni_data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are now 195 unique ENI's left to check. This is still an incredibly large amount of work to check manually. Thus, we will write an algorithm that helps us solve this. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eni_data = eni_data.drop(['Occurances','Same name'], axis=1)\n",
    "eni_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eni_data['Most frequently occuring name for this ENI'] = [eni_data[eni_data['ENI']==x].sort_values(by=\"Count\", ascending=False).reset_index()['Scheepsnaam'][0] for x in eni_data['ENI']]\n",
    "eni_data['Difference in characters'] = [jellyfish.damerau_levenshtein_distance(\n",
    "    eni_data['Scheepsnaam'][x],\n",
    "    eni_data['Most frequently occuring name for this ENI'][x]\n",
    ") for x in eni_data.index]\n",
    "\n",
    "eni_data = eni_data[eni_data['Difference in characters'] > 0]\n",
    "eni_data.sort_values(by='Difference in characters', ascending=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that many of the names with small differences in characters are very similar. We can assume that these are the same boats. We'll filter based on difference in characters <= 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eni_data = eni_data[eni_data['Difference in characters'] > 3]\n",
    "print(\"Unique ENI's left: {w}\".format(w=len(set(eni_data['ENI']))))\n",
    "eni_data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "184 ENI's left. Let's find out what the most frequently occuring ENI IDs are for these names. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eni_data['Most freq. occuring ENI for this ship name'] = [evides[['ENI','Scheepsnaam']][evides['Scheepsnaam']==x].groupby(by='ENI').size().sort_values(ascending=False).index[0] for x in eni_data['Scheepsnaam']]\n",
    "eni_data['Corresponding count'] = [evides[['ENI','Scheepsnaam']][evides['Scheepsnaam']==x].groupby(by='ENI').size().sort_values(ascending=False)[0] for x in eni_data['Scheepsnaam']]\n",
    "eni_data[['ENI','Scheepsnaam','Count','Most freq. occuring ENI for this ship name','Corresponding count']]\n",
    "\n",
    "eni_data = eni_data[['ENI','Scheepsnaam','Count','Most freq. occuring ENI for this ship name', 'Corresponding count']][eni_data['ENI'] != eni_data['Most freq. occuring ENI for this ship name']]\n",
    "eni_data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! As can be gathered from the table above, these ENIs are extremely similar yet slightly different. Using this table as our input, we'll replace the ENI's for these ENI-Ship name combinations with the most frequently occuring ENI for the corresponding ship name. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in eni_data.index:\n",
    "    # Get information\n",
    "    ENI = eni_data.loc[i]['ENI']\n",
    "    Scheepsnaam = eni_data.loc[i]['Scheepsnaam']\n",
    "    NEW_ENI = eni_data.loc[i]['Most freq. occuring ENI for this ship name']\n",
    "    \n",
    "    # Replace values\n",
    "    evides['ENI'][(evides['ENI'] == ENI) & (evides['Scheepsnaam'] == Scheepsnaam)] = NEW_ENI"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now this is done, we can continue with the rest of the data cleaning. Since we'll be looking at time trends, we'll create a column called \"Months\" which tracks the month for every delivery."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evides['Month'] = evides['Datum'].dt.strftime('%B')\n",
    "evides['Month'] = pd.Categorical(evides['Month'], categories=['January', 'February', 'March', 'April', 'May', 'June', 'July', 'August', 'September', 'October', 'November', 'December'], ordered=True)\n",
    "evides['Month_number'] = evides['Datum'].dt.strftime('%m')\n",
    "evides = evides.sort_values(by='Datum')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a further look at the data. Since there are five boats in total, we'd expect five unique values in the ['Waterboot'] column. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(evides['Waterboot'].values)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yet, there is a sixth called 'wal'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evides[evides['Waterboot']=='wal']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It only concerns two observations, so we can remove them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evides = evides.loc[evides.Waterboot != 'wal']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, what about the districts? These are stored in the 'Wijk' column. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(evides['Wijk'].values)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There should only be four districts, but here there are five. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evides[evides['Wijk']==5]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fortunately, it only concerns four observations. Upon further inspection, the locations of each of these shipments is in or near Dordrecht. For this research project, these locations are not relevant. Therefore, these observations will be removed. In addition, we will convert the 'Wijk' column datatype to 'category', since its values represent district names. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evides = evides.loc[evides.Wijk != 5]\n",
    "evides['Wijk'] = evides['Wijk'].astype('object')\n",
    "evides.dropna(inplace=True) # remove remaing NA values"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us do one more final check."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evides.dtypes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great, now let's save our cleaned and formatted dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evides.to_csv('../Data/Cleaned data/evides_cleaned.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9d4ed44c6a2a13ca6ab9393ffa30cf54197e027a07f139da5103fcdd4e6439bc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
